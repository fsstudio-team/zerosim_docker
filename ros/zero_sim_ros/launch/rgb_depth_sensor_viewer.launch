<?xml version="1.0"?>
<launch>

    <!-- Launch file to view RGB-Depth sensor camera.
        See Unity scene: ROSDepthImagePublish_test.scene
    -->

    <!-- launch basic unity editor functionality -->
    <include file="$(find zero_sim_ros)/launch/basic_unity_editor.launch"/>

    <!-- Launch depth_image_proc nodelet 
        This converts the raw rgb8 image and the float32 depth image (in millimeters) to
        a ROS PointCloud2.
        See:  http://wiki.ros.org/depth_image_proc and note the `depth_image_proc/point_cloud_xyzrgb`
    -->
    <node pkg="nodelet" type="nodelet" name="points_xyzrgb" args="standalone depth_image_proc/point_cloud_xyzrgb"/>

    <!-- start rviz with a point cloud visualizer configuration-->
    <node type="rviz" name="rviz" pkg="rviz" args="-d $(find zero_sim_ros)/rviz/pointcloud2.rviz" />

    <node pkg="octomap_server" type="octomap_server_node" name="octomap_server">
        <param name="resolution" value="0.25" />

        <!--common frame id fixed map frame (set to 'map' if SLAM or localization running!) -->
        <param name="frame_id" type="string" value="world" />

        <!-- maximum range to integrate (speedup!) -->
        <param name="sensor_model/max_range" value="10.0" />

        <!-- data source to integrate (PointCloud2) -->
        <remap from="cloud_in" to="/depth_registered/points" />

    </node>
</launch>